# WaveLabel - éŸ³é¢‘æ³¢å½¢æ ‡æ³¨ä¸è®­ç»ƒç³»ç»Ÿ

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

ä¸€ä¸ªç”¨äºæå–éŸ³é¢‘æ³¢å½¢ã€äººå·¥æ ‡æ³¨ä»¥åŠè®­ç»ƒåˆ†ç±»æ¨¡å‹çš„å®Œæ•´å·¥å…·é“¾ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ§ éŸ³é¢‘æ³¢å½¢æå–ä¸å¯è§†åŒ–
- ğŸ·ï¸ ç›´è§‚çš„æ³¢å½¢æ ‡æ³¨ç•Œé¢
- ğŸ“Š æ ‡æ³¨æ•°æ®ç®¡ç†ä¸å¯¼å‡º
- ğŸ¤– è‡ªåŠ¨è®­ç»ƒæ³¢å½¢åˆ†ç±»æ¨¡å‹
- ğŸ“ˆ æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸å¯è§†åŒ–

## é¡¹ç›®ç»“æ„

```bash
AudioAnnotationTool/
â”œâ”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ requirements.txt        # Pythonä¾èµ–
â”œâ”€â”€ config.yaml             # é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ data/                   # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw_audio/          # åŸå§‹éŸ³é¢‘æ–‡ä»¶
â”‚   â”œâ”€â”€ extracted_waves/    # æå–çš„æ³¢å½¢ç‰‡æ®µ
â”‚   â”œâ”€â”€ labeled_data/       # å·²æ ‡æ³¨æ•°æ®
â”‚   â””â”€â”€ datasets/           # è®­ç»ƒ/æµ‹è¯•æ•°æ®é›†
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ wave_extractor.py   # æ³¢å½¢æå–æ¨¡å—
â”‚   â”œâ”€â”€ annotation_tool/    # æ ‡æ³¨å·¥å…·ç•Œé¢
â”‚   â”‚   â”œâ”€â”€ gui.py          # å›¾å½¢ç•Œé¢
â”‚   â”‚   â””â”€â”€ cli.py          # å‘½ä»¤è¡Œç•Œé¢
â”‚   â”œâ”€â”€ data_processor.py   # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ model_trainer.py    # æ¨¡å‹è®­ç»ƒ
â”‚   â””â”€â”€ evaluator.py        # æ¨¡å‹è¯„ä¼°
â”‚
â”œâ”€â”€ models/                 # è®­ç»ƒå¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ pretrained/         # é¢„è®­ç»ƒæ¨¡å‹
â”‚   â””â”€â”€ trained/            # è‡ªå®šä¹‰è®­ç»ƒæ¨¡å‹
â”‚
â”œâ”€â”€ notebooks/              # Jupyterç¬”è®°æœ¬
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â””â”€â”€ model_testing.ipynb
â”‚
â””â”€â”€ docs/                   # æ–‡æ¡£
    â”œâ”€â”€ user_guide.md       # ç”¨æˆ·æŒ‡å—
    â””â”€â”€ developer_guide.md  # å¼€å‘è€…æŒ‡å—
```

```markdown
## å¿«é€Ÿå¼€å§‹

1. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

2. æå–éŸ³é¢‘æ³¢å½¢ï¼š
```bash
python src/wave_extractor.py -i data/raw_audio/ -o data/extracted_waves/
```

3. å¯åŠ¨æ ‡æ³¨å·¥å…·ï¼š
```bash
python src/annotation_tool/gui.py
```

4. è®­ç»ƒæ¨¡å‹ï¼š
```bash
python src/model_trainer.py --data data/labeled_data/ --output models/trained/
```

## æ•°æ®æµç¨‹

1. **æ³¢å½¢æå–**ï¼šä»é•¿éŸ³é¢‘ä¸­åˆ†å‰²å‡ºæœ‰æ„ä¹‰çš„æ³¢å½¢ç‰‡æ®µ
2. **äººå·¥æ ‡æ³¨**ï¼šé€šè¿‡GUIå·¥å…·ä¸ºæ³¢å½¢æ‰“æ ‡ç­¾
3. **æ¨¡å‹è®­ç»ƒ**ï¼šä½¿ç”¨æ ‡æ³¨æ•°æ®è®­ç»ƒåˆ†ç±»å™¨
4. **æ€§èƒ½è¯„ä¼°**ï¼šæµ‹è¯•æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°

## æŠ€æœ¯æ ˆ

- éŸ³é¢‘å¤„ç†ï¼šlibrosa, pydub
- æ•°æ®æ ‡æ³¨ï¼šPyQt/PySide æˆ– Tkinter
- æœºå™¨å­¦ä¹ ï¼šscikit-learn, TensorFlow/PyTorch
- å¯è§†åŒ–ï¼šmatplotlib, seaborn

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Pull Requestï¼è¯·å…ˆé˜…è¯»[è´¡çŒ®æŒ‡å—](docs/contributing.md)ã€‚

## è®¸å¯è¯

MIT License
```

## æ ¸å¿ƒä»£ç å®ç°å»ºè®®

### 1. æ³¢å½¢æå– (`wave_extractor.py`)
```python
import librosa
import numpy as np
import os

def extract_waveforms(input_dir, output_dir, segment_length=5.0, sr=22050):
    """ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–å›ºå®šé•¿åº¦çš„æ³¢å½¢ç‰‡æ®µ"""
    os.makedirs(output_dir, exist_ok=True)
    
    for file in os.listdir(input_dir):
        if file.endswith('.wav') or file.endswith('.mp3'):
            path = os.path.join(input_dir, file)
            y, sr = librosa.load(path, sr=sr)
            
            # è®¡ç®—åˆ†æ®µæ•°
            samples_per_segment = int(segment_length * sr)
            n_segments = len(y) // samples_per_segment
            
            for i in range(n_segments):
                start = i * samples_per_segment
                end = start + samples_per_segment
                segment = y[start:end]
                
                # ä¿å­˜æ³¢å½¢ç‰‡æ®µ
                np.save(os.path.join(output_dir, f"{file[:-4]}_seg{i}.npy"), segment)
```

### 2. æ ‡æ³¨å·¥å…·ç•Œé¢ (`annotation_tool/gui.py`)
```python
from PyQt5.QtWidgets import (QApplication, QMainWindow, QLabel, 
                            QPushButton, QVBoxLayout, QWidget)
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas

class AnnotationTool(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("WaveLabel - æ³¢å½¢æ ‡æ³¨å·¥å…·")
        self.setGeometry(100, 100, 800, 600)
        
        # åˆå§‹åŒ–UI
        self.init_ui()
        self.current_index = 0
        self.waveforms = []  # åŠ è½½æ³¢å½¢æ•°æ®
        
    def init_ui(self):
        # åˆ›å»ºmatplotlibå›¾å½¢
        self.figure, self.ax = plt.subplots()
        self.canvas = FigureCanvas(self.figure)
        
        # åˆ›å»ºæ§ä»¶
        self.label = QLabel("æ³¢å½¢æ ‡æ³¨")
        self.prev_btn = QPushButton("ä¸Šä¸€ä¸ª")
        self.next_btn = QPushButton("ä¸‹ä¸€ä¸ª")
        self.save_btn = QPushButton("ä¿å­˜æ ‡æ³¨")
        
        # å¸ƒå±€
        layout = QVBoxLayout()
        layout.addWidget(self.canvas)
        layout.addWidget(self.label)
        layout.addWidget(self.prev_btn)
        layout.addWidget(self.next_btn)
        layout.addWidget(self.save_btn)
        
        container = QWidget()
        container.setLayout(layout)
        self.setCentralWidget(container)
        
        # è¿æ¥ä¿¡å·
        self.prev_btn.clicked.connect(self.show_previous)
        self.next_btn.clicked.connect(self.show_next)
        self.save_btn.clicked.connect(self.save_annotation)
        
    def show_waveform(self, index):
        """æ˜¾ç¤ºæŒ‡å®šç´¢å¼•çš„æ³¢å½¢"""
        if 0 <= index < len(self.waveforms):
            self.ax.clear()
            self.ax.plot(self.waveforms[index])
            self.canvas.draw()
            self.current_index = index

    def show_previous(self):
        self.show_waveform(self.current_index - 1)
    
    def show_next(self):
        self.show_waveform(self.current_index + 1)
    
    def save_annotation(self):
        # ä¿å­˜æ ‡æ³¨é€»è¾‘
        pass

if __name__ == "__main__":
    app = QApplication([])
    window = AnnotationTool()
    window.show()
    app.exec_()
```

### 3. æ¨¡å‹è®­ç»ƒ (`model_trainer.py`)
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import joblib
import os

def load_labeled_data(data_dir):
    """åŠ è½½å·²æ ‡æ³¨çš„æ³¢å½¢æ•°æ®å’Œæ ‡ç­¾"""
    X, y = [], []
    for file in os.listdir(data_dir):
        if file.endswith('.npy'):
            wave = np.load(os.path.join(data_dir, file))
            label = ...  # ä»é…å¥—çš„æ ‡ç­¾æ–‡ä»¶è¯»å–
            X.append(wave)
            y.append(label)
    return np.array(X), np.array(y)

def extract_features(waveforms, sr=22050):
    """ä»æ³¢å½¢ä¸­æå–ç‰¹å¾"""
    features = []
    for wave in waveforms:
        # ç¤ºä¾‹ç‰¹å¾ï¼šMFCCç³»æ•°
        mfcc = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=13)
        features.append(mfcc.mean(axis=1))
    return np.array(features)

def train_model(X_train, y_train):
    """è®­ç»ƒåˆ†ç±»æ¨¡å‹"""
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    return model

if __name__ == "__main__":
    # åŠ è½½æ•°æ®
    X, y = load_labeled_data("data/labeled_data/")
    
    # ç‰¹å¾æå–
    X_features = extract_features(X)
    
    # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X_features, y, test_size=0.2, random_state=42)
    
    # è®­ç»ƒæ¨¡å‹
    model = train_model(X_train, y_train)
    
    # è¯„ä¼°
    y_pred = model.predict(X_test)
    print(classification_report(y_test, y_pred))
    
    # ä¿å­˜æ¨¡å‹
    joblib.dump(model, "models/trained/wave_classifier.pkl")
```

è¿™ä¸ªé¡¹ç›®ç»“æ„æä¾›äº†å®Œæ•´çš„éŸ³é¢‘æ ‡æ³¨å’Œæœºå™¨å­¦ä¹ å·¥ä½œæµï¼Œæ‚¨å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å„ä¸ªæ¨¡å—çš„å®ç°ç»†èŠ‚ã€‚